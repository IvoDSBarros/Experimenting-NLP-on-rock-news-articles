# Overview
This repository is made up of multiple NLP experiments on web rock news articles. The text corpus is comprised by 20 000 article news retrieved from 6 rock specialized websites: Loudersound, loudwire, Ultimate Classic Rock (UCR), Kerrang!, Planet Rock and The New York Times (NYT). 

<details>
<summary>Table of Contents</summary>
[Rule-based text classification](#-rule-based-text-classification)
</details>

# Rule based text classification
# Goals
This rule-based text classification model is intended to identify keywords and assign both topic labels and publication type categories across a text corpus comprised by rock news headlines with no labeled data. A set of pre-defined rules has been manually created for this purpose. The core of the rock news headlines' semantic landscape consists of the keywords 'album', 'single', 'song', 'show', 'tour' and 'video'. The keywords are the foundation to set up the classification logical rules and assign human-readable contextualized tags.
<div align = "right">    
  <a href="#overview">(back to top)</a>



Use the package manager [pip](https://pip.pypa.io/en/stable/) to install foobar.

```bash
pip install foobar
```

</details>

<details><summary>Cool Dropdown #2</summary>

More cool text hiding in my dropdown

# Topic Modeling of BBC News Articles
This project is a Capstone Project done as part of Unsupervised Machine Learning. A set of 2225 BBC News Articles are analysed to identify the underlying themes and topics within them.

<details>
<summary>Table of Contents</summary>

1. [About the Project](#about-the-project)
2. [Data Reading and Description](#data-reading-and-description)
3. [Data Pre-Processing](#data-pre-processing)
4. [Model Implementation](#model-implementation)
    + [LDA Model](#1-lda-model)
    + [LSA Model](#2-lsa-model)
5. [Model Evaluation](#model-evaluation)
6. [Results](#results)
7. [Conlusion](#conclusion)
8. [Challenges Faced](#challenges-faced)
9. [Libraries Used](#libraries-used)
10. [Contact](#contact)
</details>

## About The Project

Topic modelling is a widely used technique in natural language processing that helps to extract latent topics from a large collection of documents. In the context of News Articles, it categorises these documents into various categories of requirement, which is very helpful for organisations to manage their content and for the readers as well, to easily find articles of interest.

It can also help in content summarisation by breaking down the lengthy articles into keywords and themes to briefly summarise the content in a concise manner, without loss of information.

This Project focuses on the former application, to determine the underlying topics within the corpus of News Articles. The original category of each article is provided as an input for evaluation of the topic modeling algorithm. It should be noted that these original categories are not considered as an input for modeling and is in no way influences the algorithm metholody.
<div align = "right">    
  <a href="#topic-modeling-of-bbc-news-articles">(back to top)</a>
</div>
